{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ccd35ff",
   "metadata": {},
   "source": [
    "The contents of this course including lectures, labs, homework assignments, and exams have all been adapted from the [Data 8 course at University California Berkley](https://data.berkeley.edu/education/courses/data-8). Through their generosity and passion for undergraduate education, the Data 8 community at Berkley has opened their content and expertise for other universities to adapt in the name of undergraduate education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datascience\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7ea4d",
   "metadata": {},
   "source": [
    "# Chapter 11 Testing Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e607a",
   "metadata": {},
   "source": [
    "Data scientest often times have to answer yes and no questions. How we answer these questions often depends on the data we have. In this chapter we try to answer yes-no questions using random samples and emperical distributions.\n",
    "\n",
    "### Case Study: Swain vs. Alabama 1965\n",
    "* Talladega County, Alabama\n",
    "* Robert Swain, black man convicted of crime\n",
    "* Appeal: one factor was all-white jury\n",
    "* Only men 21 years or older were allowed to serve\n",
    "* 26% of this population were black\n",
    "* Swain’s jury panel consisted of 100 men\n",
    "* 8 men on the panel were black\n",
    "* Appeal went to Supreme Court and concluded \"the overall percentage disparity has been small andreflects no studied attempt to include or exclude a specified number of Negroes”\n",
    "* The Supreme Court denied Robert Swain’s appeal\n",
    "\n",
    "#### Question: Is 8/100 a realistic outcome if the jury panel selection process was unbiased?\n",
    "\n",
    "To answer the question we will simulate random selection:\n",
    "\n",
    "* We can simulate data based on the model. That is, we can simulate drawing at random from a population of whom 26% are Black.\n",
    "* Our simulation will show what a panel would be like if it were selected at random.\n",
    "* We can then compare the results of the simulation with the composition of an actual jury panel.\n",
    "* If the results of our simulation are not consistent with the composition of the panel in the trial, that will be evidence against the model of random selection. Therefore, it will be evidence against the fairness of the trial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a88547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "eligible_population = [0.26, 0.74]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5791e7a",
   "metadata": {},
   "source": [
    "#### sample_proportions() funtion:\n",
    "sample_proportions() funtion samples at random with replacement from a categorical distribution and returns the proportions of sampled elements in each category.\n",
    "\n",
    "The sample_proportions function takes two arguments:\n",
    "* the sample size\n",
    "* the distribution of the categories in the population, as a list or array of proportions that add up to 1\n",
    "\n",
    "It returns an array containing the distribution of the categories in a random sample of the given size taken from the population. That’s an array consisting of the sample proportions in all the different categories, in the same order in which they appeared in the population distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few times. Do you ever see a sample of 0.08?\n",
    "sample_proportions(sample_size, eligible_population).item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587059f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulated_count():\n",
    "    return sample_size * sample_proportions(sample_size, eligible_population).item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb91e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = make_array()\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    counts = np.append(counts, one_simulated_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column(\n",
    "    'Count in a Random Sample', counts\n",
    ").hist(bins = np.arange(5.5, 46.6, 1))\n",
    "plots.ylim(-0.002, 0.09)\n",
    "plots.scatter(8, 0, color='red', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4238a76",
   "metadata": {},
   "source": [
    "## Another Case Study: Jury Selection in Alameda CA\n",
    "\n",
    "In 2010, the American Civil Liberties Union (ACLU) of Northern California presented a [report](https://www.aclunc.org/sites/default/files/racial_and_ethnic_disparities_in_alameda_county_jury_pools.pdf) on jury selection in Alameda County, California. The report concluded that certain racial and ethnic groups are underrepresented among jury panelists in Alameda County, and suggested some reforms of the process by which eligible jurors are assigned to panels. In this section, we will analyze the data provided by the ACLU.\n",
    "\n",
    " The ACLU compiled data on the composition of the jury panels in 11 felony trials in Alameda County in the years 2009 and 2010. In those panels, the total number of people who reported for jury service was 1453. The ACLU gathered demographic data on all of these prosepctive jurors, and compared those data with the composition of all eligible jurors in the county.\n",
    "\n",
    "The data are tabulated below in a table called jury. In each category, the first numerical value is the proportion of all eligible juror candidates in that category. The second value is the proportion of people in that category among those who appeared for the process of selection into the jury.\n",
    "\n",
    "The labels for the different categories are taken from the ACLU report, which says, “The category “other” includes people who identified as mixed race without identifying one primary racial identity, and individuals who did not identify a race or ethnicity.” The label Asian/PI means “Asian or Pacific Islander.” The label Black/AA means “Black or African-American.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad421f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury = Table().with_columns(\n",
    "    'Ethnicity', make_array('Asian/PI', 'Black/AA', 'Caucasian', 'Hispanic', 'Other'),\n",
    "    'Eligible', make_array(0.15, 0.18, 0.54, 0.12, 0.01),\n",
    "    'Panels', make_array(0.26, 0.08, 0.54, 0.08, 0.04)\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed53b6",
   "metadata": {},
   "source": [
    "What if we select a random sample of 1,453 people from the population of eligible jurors? Will the distribution of their ethnicities look like the distribution of the panels above?\n",
    "\n",
    "We can answer these questions by using sample_proportions and augmenting the jury table with a column of the proportions in our sample.\n",
    "\n",
    "**Technical note.** Random samples of prospective jurors would be selected without replacement. However, when the size of a sample is small relative to the size of the population, sampling without replacement resembles sampling with replacement; the proportions in the population don’t change much between draws. The population of eligible jurors in Alameda County is over a million, and compared to that, a sample size of about 1500 is quite small. We will therefore sample with replacement.\n",
    "\n",
    "In the cell below, we sample at random 1453 times from the distribution of eligible jurors, and display the distribution of the random sample along with the distributions of the eligible jurors and the panel in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60164b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_population = jury.column('Eligible')\n",
    "sample_distribution = sample_proportions(1453, eligible_population)\n",
    "panels_and_sample = jury.with_column('Random Sample', sample_distribution)\n",
    "panels_and_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_and_sample.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cac33c",
   "metadata": {},
   "source": [
    " We need a statistic that will help us assess whether or not the model or random selection is supported by the data. A New Statistic: The Distance between Two Distributions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_with_diffs = jury.with_column(\n",
    "    'Difference', jury.column('Panels') - jury.column('Eligible')\n",
    ")\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_with_diffs = jury_with_diffs.with_column(\n",
    "    'Absolute Difference', np.abs(jury_with_diffs.column('Difference'))\n",
    ")\n",
    "\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_with_diffs.column('Absolute Difference').sum() / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de7c2f",
   "metadata": {},
   "source": [
    "This quantity 0.14 is the total variation distance (TVD) between the distribution of ethnicities in the eligible juror population and the distribution in the panels.\n",
    "\n",
    "In general, the total variation distance between two distributions measures how close the distributions are. The larger the TVD, the more different the two distributions appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15889424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(distribution_1, distribution_2):\n",
    "    return sum(np.abs(distribution_1 - distribution_2)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variation_distance(jury.column('Panels'), jury.column('Eligible'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75011c82",
   "metadata": {},
   "source": [
    "In the cell below we use the function to compute the TVD between the distributions of the eligible jurors and one random sample. Recall that eligible_population is the array containing the distribution of the eligible jurors, and that our sample size is 1453.\n",
    "\n",
    "In the first line, we use sample_proportions to generate a random sample from the eligible population. In the next line we use total_variation_distance to compute the TVD between the distributions in the random sample and the eligible population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c59263",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_distribution = sample_proportions(1453, eligible_population)\n",
    "total_variation_distance(sample_distribution, eligible_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf033d",
   "metadata": {},
   "source": [
    "Run the cell a few times and notice that the distances are quite a bit smaller than 0.14, the distance between the distribution of the panels and the eligible jurors.\n",
    "\n",
    "We are now ready to run a simulation to assess the model of random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8248b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate one simulated value of \n",
    "# the total variation distance between\n",
    "# the distribution of a sample selected at random\n",
    "# and the distribution of the eligible population\n",
    "\n",
    "def one_simulated_tvd():\n",
    "    sample_distribution = sample_proportions(1453, eligible_population)\n",
    "    return total_variation_distance(sample_distribution, eligible_population)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvds = make_array()\n",
    "repetitions = 5000\n",
    "for i in np.arange(repetitions):\n",
    "    tvds = np.append(tvds, one_simulated_tvd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f583ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('TVD', tvds).hist(bins=np.arange(0, 0.2, 0.005))\n",
    "\n",
    "# Plotting parameters; you can ignore this code\n",
    "plots.title('Prediction Assuming Random Selection')\n",
    "plots.xlim(0, 0.15)\n",
    "plots.ylim(-5, 50)\n",
    "plots.scatter(0.14, 0, color='red', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb585a3",
   "metadata": {},
   "source": [
    "The simulation shows that the composition of the panels in the ACLU study is not consistent with the model of random selection. Our analysis supports the ACLU’s conclusion that the panels were not representative of the distribution provided for the eligible jurors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb15e60",
   "metadata": {},
   "source": [
    "### Another Case Study:  Mendel's Pea Plants\n",
    "\n",
    "[Gregor Mendel](https://en.wikipedia.org/wiki/Gregor_Mendel) (1822-1884) was an Austrian monk who is widely recognized as the founder of the modern field of genetics. Mendel performed careful and large-scale experiments on plants to come up with fundamental laws of genetics.\n",
    "\n",
    "Many of his experiments were on varieties of pea plants. He formulated sets of assumptions about each variety; these were his models. He then tested the validity of his models by growing the plants and gathering data.\n",
    "\n",
    "For pea plants of a particular variety, Mendel proposed the following model.\n",
    "\n",
    "For every plant, there is a 75% chance that it will have purple flowers, and a 25% chance that the flowers will be white, regardless of the colors in all the other plants.\n",
    "\n",
    "To see whether his model was valid, Mendel grew 929 pea plants of this variety. Among these 929 plants, 705 had purple flowers.\n",
    "\n",
    "We will use these data to perform a test of hypotheses and see if Mendel’s model looks good.\n",
    "\n",
    "All statistical tests attempt to choose between two views of the world. Specifically, the choice is between two views about how the data were generated. These two views are called hypotheses.\n",
    "\n",
    "**The null hypothesis.** This is a clearly defined model about chances. It says that the data were generated at random under clearly specified assumptions about the randomness. The word “null” reinforces the idea that if the data look different from what the null hypothesis predicts, the difference is due to nothing but chance.\n",
    "\n",
    "From a practical perspective, **the null hypothesis is a hypothesis under which you can simulate data.**\n",
    "\n",
    "In the example about Mendel’s model for the colors of pea plants, the null hypothesis is that the assumptions of his model are good: each plant has a 75% chance of having purple flowers, independent of all other plants.\n",
    "\n",
    "Under this hypothesis, we can simulate random samples by using sample_proportions.\n",
    "\n",
    "The alternative hypothesis. This says that some reason other than chance made the data differ from the predictions of the model in the null hypothesis.\n",
    "\n",
    "In the example about Mendel’s plants, the alternative hypothesis is simply that his model isn’t good.\n",
    "\n",
    "Keep in mind that the alternative doesn’t say how or why the model isn’t good. It just says the model isn’t good.\n",
    "\n",
    "In order to decide between the two hypothesis, we must choose a statistic that we can use to make the decision. This is called the **test statistic.**\n",
    "\n",
    "We will be comparing two categorical distributions: the one in Mendel’s model and the one we will get in our random sample. We want to see if these two distributions are close to each other or far apart. So a natural test statistic is the total variation distance (TVD).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795948e",
   "metadata": {},
   "source": [
    "The observed value of the test statistic is the value of the statistic you get from the data in the study, not a simulated value. Among Mendel’s 929 plants, 705 had purple flowers. The observed value of the test statistic was therefore\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb124fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_statistic = abs ( 100 * (705 / 929) - 75)\n",
    "observed_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e599fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mendel_proportions = make_array(0.75, 0.25)\n",
    "mendel_proportion_purple = mendel_proportions.item(0)\n",
    "sample_size = 929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90db6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulated_distance():\n",
    "    sample_proportion_purple = sample_proportions(929, mendel_proportions).item(0)\n",
    "    return 100 * abs(sample_proportion_purple - mendel_proportion_purple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 10000\n",
    "distances = make_array()\n",
    "for i in np.arange(repetitions):\n",
    "    distances = np.append(distances, one_simulated_distance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column(\n",
    "    'Distance between Sample % and 75%', distances\n",
    ").hist()\n",
    "plots.ylim(-0.02, 0.5)\n",
    "plots.title('Prediction Made by the Null Hypothesis')\n",
    "plots.scatter(observed_statistic, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2defe",
   "metadata": {},
   "source": [
    "The observed statistic is like a typical distance predicted by the null hypothesis. The null hypothesis is Mendel’s model. So our test concludes that the data are consistent with Mendel’s model and we accept the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ebaea",
   "metadata": {},
   "source": [
    "In all of our examples of assessing models there has been no doubt about whether the data were consistent with the model’s predictions. They were either very far from what the model predicted, as in the examples about jury panels, or similar to what the model predicted, as in the example about Mendel’s model.\n",
    "\n",
    "But outcomes are not always so clear cut. How far is “far”? Exactly what should “similar” mean? While these questions don’t have universal answers, there are some guidelines and conventions that you can follow.\n",
    "\n",
    "Suppose someone grew another 929 plants of some related variety and wanted to see if Mendel’s model worked for plants of that variety too. What would you conclude if their observed distance came out to be 3.2 as shown below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f702714",
   "metadata": {},
   "outputs": [],
   "source": [
    "different_observed_statistic = 3.2\n",
    "Table().with_column(\n",
    "    'Distance between Sample % and 75%', distances\n",
    ").hist()\n",
    "plots.ylim(-0.02, 0.5)\n",
    "plots.title('Prediction Made by the Null Hypothesis')\n",
    "plots.scatter(different_observed_statistic, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5822744",
   "metadata": {},
   "source": [
    "The conventions are based on the area in the tail, starting at the observed statistic (the red dot) and looking in the direction that makes us lean toward the alternative. In this example that’s the right side, because big distances favor the alternative which says that the model isn’t good.\n",
    "\n",
    "If the area of the tail is small, the observed statistic is far away from the values most commonly predicted by the null hypothesis.\n",
    "\n",
    "Remember that in a histogram, area represents percent. To find the area in the tail, we have to find the percent of distances that were greater than or equal to 3.2, where the red dot is. The array distances contains the averages for all 10,000 repetitions of random sampling under Mendel’s model, and different_observed_statistic is 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ed7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(distances >= different_observed_statistic) / repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72027a7e",
   "metadata": {},
   "source": [
    "We can conclude that if Mendel’s model were correct for these new plants, then there is about a 2.5% chance that the test statistic would be 3.2 or more.\n",
    "\n",
    "That doesn’t seem like a big chance. If Mendel’s model is true for these plants, something quite unlikely has happened. This idea gives rise to the conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed6ae5",
   "metadata": {},
   "source": [
    "This chance has an impressive name. It is called the observed significance level of the test. That’s a mouthful, and so it is commonly called the p-value of the test.\n",
    "\n",
    "Definition: The p-value of a test is the chance, based on the model in the null hypothesis, that the test statistic will be equal to the observed value in the sample or even further in the direction that supports the alternative.\n",
    "\n",
    "If a p-value is small, that means the tail beyond the observed statistic is small and so the observed statistic is far away from what the null predicts. This implies that the data support the alternative hypothesis more than they support the null.\n",
    "\n",
    "How small is “small”? According to the conventions:\n",
    "\n",
    "* If the p-value is less than 5%, it is considered small and the result is called “statistically significant.”\n",
    "\n",
    "* If the p-value is even smaller – less than 1% – the result is called “highly statistically significant.”\n",
    "\n",
    "By this convention, our p-value of 2.5% is considered small. So the conventional conclusion would be to reject the null hypothesis and say that Mendel’s model does not look good for the new plants. Formally, the result of the test is statistically significant.\n",
    "\n",
    "Whether you use a conventional cutoff or your own judgment, it is important to keep the following points in mind.\n",
    "\n",
    "* Always provide the observed value of the test statistic and the p-value, so that readers can decide whether or not they think the p-value is small.\n",
    "\n",
    "* Don’t look to defy convention only when the conventionally derived result is not to your liking.\n",
    "\n",
    "* Even if a test concludes that the data don’t support the chance model in the null hypothesis, it typically doesn’t explain why the model doesn’t work. Don’t make causal conclusions without further analysis, unless you are running a randomized controlled trial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a0f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
